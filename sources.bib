@article{akshathaHumanDetectionAerial2022,
  title = {Human {{Detection}} in {{Aerial Thermal Images Using Faster R-CNN}} and {{SSD Algorithms}}},
  author = {Akshatha, K. R. and Karunakar, A. Kotegar and Shenoy, Satish B. and Pai, Abhilash K. and Nagaraj, Nikhil Hunjanal and Rohatgi, Sambhav Singh},
  year = {2022},
  month = jan,
  journal = {Electronics},
  volume = {11},
  number = {7},
  pages = {1151},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2079-9292},
  doi = {10.3390/electronics11071151},
  urldate = {2025-07-29},
  abstract = {The automatic detection of humans in aerial thermal imagery plays a significant role in various real-time applications, such as surveillance, search and rescue and border monitoring. Small target size, low resolution, occlusion, pose, and scale variations are the significant challenges in aerial thermal images that cause poor performance for various state-of-the-art object detection algorithms. Though many deep-learning-based object detection algorithms have shown impressive performance for generic object detection tasks, their ability to detect smaller objects in the aerial thermal images is analyzed through this study. This work carried out the performance evaluation of Faster R-CNN and single-shot multi-box detector (SSD) algorithms with different backbone networks to detect human targets in aerial view thermal images. For this purpose, two standard aerial thermal datasets having human objects of varying scale are considered with different backbone networks, such as ResNet50, Inception-v2, and MobileNet-v1. The evaluation results demonstrate that the Faster R-CNN model trained with the ResNet50 network architecture out-performed in terms of detection accuracy, with a mean average precision (mAP at 0.5 IoU) of 100\% and 55.7\% for the test data of the OSU thermal dataset and AAU PD T datasets, respectively. SSD with MobileNet-v1 achieved the highest detection speed of 44 frames per second (FPS) on the NVIDIA GeForce GTX 1080 GPU. Fine-tuning the anchor parameters of the Faster R-CNN ResNet50 and SSD Inception-v2 algorithms caused remarkable improvement in mAP by 10\% and 3.5\%, respectively, for the challenging AAU PD T dataset. The experimental results demonstrated the application of Faster R-CNN and SSD algorithms for human detection in aerial view thermal images, and the impact of varying backbone network and anchor parameters on the performance improvement of these algorithms.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {aerial images,convolutional neural network,Faster RCNN,human detection,object detection,SSD,thermal camera},
  file = {/Users/lukas/Zotero/storage/5AEQKNYM/Akshatha et al. - 2022 - Human Detection in Aerial Thermal Images Using Faster R-CNN and SSD Algorithms.pdf}
}

@misc{alqahtaniBenchmarkingDeepLearning2024,
  title = {Benchmarking {{Deep Learning Models}} for {{Object Detection}} on {{Edge Computing Devices}}},
  author = {Alqahtani, Daghash K. and Cheema, Aamir and Toosi, Adel N.},
  year = {2024},
  month = sep,
  number = {arXiv:2409.16808},
  eprint = {2409.16808},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2409.16808},
  urldate = {2025-08-13},
  abstract = {Modern applications, such as autonomous vehicles, require deploying deep learning algorithms on resource-constrained edge devices for real-time image and video processing. However, there is limited understanding of the efficiency and performance of various object detection models on these devices. In this paper, we evaluate state-of-the-art object detection models, including YOLOv8 (Nano, Small, Medium), EfficientDet Lite (Lite0, Lite1, Lite2), and SSD (SSD MobileNet V1, SSDLite MobileDet). We deployed these models on popular edge devices like the Raspberry Pi 3, 4, and 5 with/without TPU accelerators, and Jetson Orin Nano, collecting key performance metrics such as energy consumption, inference time, and Mean Average Precision (mAP). Our findings highlight that lower mAP models such as SSD MobileNet V1 are more energy-efficient and faster in inference, whereas higher mAP models like YOLOv8 Medium generally consume more energy and have slower inference, though with exceptions when accelerators like TPUs are used. Among the edge devices, Jetson Orin Nano stands out as the fastest and most energy-efficient option for request handling, despite having the highest idle energy consumption. These results emphasize the need to balance accuracy, speed, and energy efficiency when deploying deep learning models on edge devices, offering valuable guidance for practitioners and researchers selecting models and devices for their applications.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Distributed Parallel and Cluster Computing,Computer Science - Hardware Architecture,Computer Science - Software Engineering},
  file = {/Users/lukas/Zotero/storage/LJDTB96N/Alqahtani et al. - 2024 - Benchmarking Deep Learning Models for Object Detection on Edge Computing Devices.pdf;/Users/lukas/Zotero/storage/SRXB2BWI/2409.html}
}

@inproceedings{beyererCNNbasedThermalInfrared2018,
  title = {{{CNN-based}} Thermal Infrared Person Detection by Domain Adaptation},
  booktitle = {Autonomous {{Systems}}: {{Sensors}}, {{Vehicles}}, {{Security}}, and the {{Internet}} of {{Everything}}},
  author = {Beyerer, J{\"u}rgen and Ruf, Miriam and Herrmann, Christian},
  editor = {Dudzik, Michael C. and Ricklin, Jennifer C.},
  year = {2018},
  month = may,
  pages = {8},
  publisher = {SPIE},
  address = {Orlando, United States},
  doi = {10.1117/12.2304400},
  urldate = {2025-08-12},
  abstract = {Imaging sensors capturing the surroundings of an autonomous vehicle are vital for its understanding of the environment. While thermal infrared cameras promise improved bad weather and nighttime robustness compared with standard RGBcameras, detecting objects, such as persons, in thermal infrared imagery is a tough problem because image resolution and quality is typically far lower, especially for low-cost sensors. Currently, deep learning based object detection frameworks offer an impressive performance on high-quality images. However, applying them to low-quality data in a different spectral range causes significant performance drops. This work proposes a strategy to make use of elaborate CNN-based object detector frameworks which are pre-trained on visual RGB images. Two key steps are undertaken: First, an appropriate preprocessing strategy for the IR data is suggested which transforms the IR data as close as possible to the RGB domain. This allows pre-trained RGB features to be effective on the novel domain. Second, the remaining domain gap is addressed by fine-tuning the pre-trained CNN on a limited set of thermal IR data. Different IR preprocessing options are explored, each addressing a different aspect of the domain gap between thermal IR and RGB data. Examples include dynamic range, blur or contrast. Because no preprocessing can cover all aspects alone, providing preprocessing combinations to the CNN allows addressing more than one aspect at once and further improves the results. Experiments indicate significant person detection improvements on the public KAIST dataset with the optimized preprocessing strategy.},
  isbn = {978-1-5106-1797-1 978-1-5106-1798-8},
  langid = {english},
  file = {/Users/lukas/Zotero/storage/D2XA5X3L/Beyerer et al. - 2018 - CNN-based thermal infrared person detection by domain adaptation.pdf}
}

@article{cortesSupportvectorNetworks1995,
  title = {Support-Vector Networks},
  author = {Cortes, Corinna and Vapnik, Vladimir},
  year = {1995},
  month = sep,
  journal = {Machine Learning},
  volume = {20},
  number = {3},
  pages = {273--297},
  issn = {1573-0565},
  doi = {10.1007/BF00994018},
  urldate = {2025-08-12},
  abstract = {Thesupport-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high-dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data.},
  langid = {english},
  keywords = {efficient learning algorithms,neural networks,pattern recognition,polynomial classifiers,radial basis function classifiers},
  file = {/Users/lukas/Zotero/storage/R8KFXDXX/Cortes and Vapnik - 1995 - Support-vector networks.pdf}
}

@inproceedings{dalalHistogramsOrientedGradients2005,
  title = {Histograms of {{Oriented Gradients}} for {{Human Detection}}},
  booktitle = {2005 {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}}'05)},
  author = {Dalal, N. and Triggs, B.},
  year = {2005},
  volume = {1},
  pages = {886--893},
  publisher = {IEEE},
  address = {San Diego, CA, USA},
  doi = {10.1109/CVPR.2005.177},
  urldate = {2025-08-12},
  abstract = {We study the question of feature sets for robust visual object recognition, adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of Histograms of Oriented Gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds.},
  isbn = {978-0-7695-2372-9},
  langid = {english},
  file = {/Users/lukas/Zotero/storage/QY8RQJT7/Dalal and Triggs - 2005 - Histograms of Oriented Gradients for Human Detection.pdf}
}

@inproceedings{davisTwoStageTemplateApproach2005,
  title = {A {{Two-Stage Template Approach}} to {{Person Detection}} in {{Thermal Imagery}}},
  booktitle = {2005 {{Seventh IEEE Workshops}} on {{Applications}} of {{Computer Vision}} ({{WACV}}/{{MOTION}}'05) - {{Volume}} 1},
  author = {Davis, James W. and Keck, Mark A.},
  year = {2005},
  month = jan,
  volume = {1},
  pages = {364--369},
  doi = {10.1109/ACVMOT.2005.14},
  urldate = {2025-08-12},
  abstract = {We present a two-stage template-based method to detect people in widely varying thermal imagery. The approach initially performs a fast screening procedure using a generalized template to locate potential person locations. Next an AdaBoosted ensemble classifier using automatically tuned filters is employed to test the hypothesized person locations. We demonstrate and evaluate the approach using a challenging dataset of thermal imagery},
  keywords = {Automatic testing,Cameras,Computer science,Computer vision,Filter bank,Humans,Pixel,Shape,Thermal engineering,Video surveillance},
  file = {/Users/lukas/Zotero/storage/AEUHIRTF/4129504.html}
}

@inproceedings{davisTwoStageTemplateApproach2005a,
  title = {A {{Two-Stage Template Approach}} to {{Person Detection}} in {{Thermal Imagery}}},
  booktitle = {2005 {{Seventh IEEE Workshops}} on {{Applications}} of {{Computer Vision}} ({{WACV}}/{{MOTION}}'05) - {{Volume}} 1},
  author = {Davis, J.W. and Keck, M.A.},
  year = {2005},
  month = jan,
  pages = {364--369},
  publisher = {IEEE},
  address = {Breckenridge, CO},
  doi = {10.1109/ACVMOT.2005.14},
  urldate = {2025-08-12},
  abstract = {We present a two-stage template-based method to detect people in widely varying thermal imagery. The approach initially performs a fast screening procedure using a generalized template to locate potential person locations. Next an AdaBoosted ensemble classifier using automatically tuned filters is employed to test the hypothesized person locations. We demonstrate and evaluate the approach using a challenging dataset of thermal imagery.},
  isbn = {978-0-7695-2271-5},
  langid = {english},
  file = {/Users/lukas/Zotero/storage/T35VWLF3/Davis and Keck - 2005 - A Two-Stage Template Approach to Person Detection in Thermal Imagery.pdf}
}

@misc{dosovitskiyImageWorth16x162021,
  title = {An {{Image}} Is {{Worth}} 16x16 {{Words}}: {{Transformers}} for {{Image Recognition}} at {{Scale}}},
  shorttitle = {An {{Image}} Is {{Worth}} 16x16 {{Words}}},
  author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  year = {2021},
  month = jun,
  number = {arXiv:2010.11929},
  eprint = {2010.11929},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2010.11929},
  urldate = {2025-08-13},
  abstract = {While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  note = {Comment: Fine-tuning code and pre-trained models are available at https://github.com/google-research/vision\_transformer. ICLR camera-ready version with 2 small modifications: 1) Added a discussion of CLS vs GAP classifier in the appendix, 2) Fixed an error in exaFLOPs computation in Figure 5 and Table 6 (relative performance of models is basically not affected)},
  file = {/Users/lukas/Zotero/storage/JT5NHHRZ/Dosovitskiy et al. - 2021 - An Image is Worth 16x16 Words Transformers for Image Recognition at Scale.pdf;/Users/lukas/Zotero/storage/B35J7PNG/2010.html}
}

@misc{farooqObjectDetectionThermal2021,
  title = {Object {{Detection}} in {{Thermal Spectrum}} for {{Advanced Driver-Assistance Systems}} ({{ADAS}})},
  author = {Farooq, Muhammad Ali and Corcoran, Peter and Rotariu, Cosmin and Shariff, Waseem},
  year = {2021},
  month = oct,
  number = {arXiv:2109.09854},
  eprint = {2109.09854},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2109.09854},
  urldate = {2025-07-29},
  abstract = {Object detection in thermal infrared spectrum provides more reliable data source in low-lighting conditions and different weather conditions, as it is useful both in-cabin and outside for pedestrian, animal, and vehicular detection as well as for detecting street-signs \& lighting poles. This paper is about exploring and adapting state-of-the-art object detection and classifier framework on thermal vision with seven distinct classes for advanced driver-assistance systems (ADAS). The trained network variants on public datasets are validated on test data with three different test approaches which include test-time with no augmentation, test-time augmentation, and test-time with model ensembling. Additionally, the efficacy of trained networks is tested on locally gathered novel test-data captured with an uncooled LWIR prototype thermal camera in challenging weather and environmental scenarios. The performance analysis of trained models is investigated by computing precision, recall, and mean average precision scores (mAP). Furthermore, the trained model architecture is optimized using TensorRT inference accelerator and deployed on resource-constrained edge hardware Nvidia Jetson Nano to explicitly reduce the inference time on GPU as well as edge devices for further real-time onboard installations.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  note = {Comment: This work is carried under EU funded project (https://www.heliaus.eu/)},
  file = {/Users/lukas/Zotero/storage/9N4V7C9D/Farooq et al. - 2021 - Object Detection in Thermal Spectrum for Advanced Driver-Assistance Systems (ADAS).pdf;/Users/lukas/Zotero/storage/IW4UM65G/2109.html}
}

@article{fukushimaNeocognitronSelforganizingNeural1980,
  title = {Neocognitron: {{A}} Self-Organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position},
  shorttitle = {Neocognitron},
  author = {Fukushima, Kunihiko},
  year = {1980},
  month = apr,
  journal = {Biological Cybernetics},
  volume = {36},
  number = {4},
  pages = {193--202},
  issn = {1432-0770},
  doi = {10.1007/BF00344251},
  urldate = {2025-08-13},
  abstract = {A neural network model for a mechanism of visual pattern recognition is proposed in this paper. The network is self-organized by ``learning without a teacher'', and acquires an ability to recognize stimulus patterns based on the geometrical similarity (Gestalt) of their shapes without affected by their positions. This network is given a nickname ``neocognitron''. After completion of self-organization, the network has a structure similar to the hierarchy model of the visual nervous system proposed by Hubel and Wiesel. The network consits of an input layer (photoreceptor array) followed by a cascade connection of a number of modular structures, each of which is composed of two layers of cells connected in a cascade. The first layer of each module consists of ``S-cells'', which show characteristics similar to simple cells or lower order hypercomplex cells, and the second layer consists of ``C-cells'' similar to complex cells or higher order hypercomplex cells. The afferent synapses to each S-cell have plasticity and are modifiable. The network has an ability of unsupervised learning: We do not need any ``teacher'' during the process of self-organization, and it is only needed to present a set of stimulus patterns repeatedly to the input layer of the network. The network has been simulated on a digital computer. After repetitive presentation of a set of stimulus patterns, each stimulus pattern has become to elicit an output only from one of the C-cell of the last layer, and conversely, this C-cell has become selectively responsive only to that stimulus pattern. That is, none of the C-cells of the last layer responds to more than one stimulus pattern. The response of the C-cells of the last layer is not affected by the pattern's position at all. Neither is it affected by a small change in shape nor in size of the stimulus pattern.},
  langid = {english},
  keywords = {Complex Cell,Digital Computer,Input Layer,Neural Network Model,Pattern Recognition},
  file = {/Users/lukas/Zotero/storage/HY4BAPCG/Fukushima - 1980 - Neocognitron A self-organizing neural network model for a mechanism of pattern recognition unaffect.pdf}
}

@misc{heDeepResidualLearning2015,
  title = {Deep {{Residual Learning}} for {{Image Recognition}}},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  year = {2015},
  month = dec,
  number = {arXiv:1512.03385},
  eprint = {1512.03385},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1512.03385},
  urldate = {2025-08-12},
  abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  note = {Comment: Tech report},
  file = {/Users/lukas/Zotero/storage/QI2L2QUP/He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf;/Users/lukas/Zotero/storage/KLBKCGNX/1512.html}
}

@article{hudaEffectDiverseDataset2020,
  title = {The {{Effect}} of a {{Diverse Dataset}} for {{Transfer Learning}} in {{Thermal Person Detection}}},
  author = {Huda, Noor Ul and Hansen, Bolette D. and Gade, Rikke and Moeslund, Thomas B.},
  year = {2020},
  month = jan,
  journal = {Sensors},
  volume = {20},
  number = {7},
  pages = {1982},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1424-8220},
  doi = {10.3390/s20071982},
  urldate = {2025-07-29},
  abstract = {Thermal cameras are popular in detection for their precision in surveillance in the dark and for privacy preservation. In the era of data driven problem solving approaches, manually finding and annotating a large amount of data is inefficient in terms of cost and effort. With the introduction of transfer learning, rather than having large datasets, a dataset covering all characteristics and aspects of the target place is more important. In this work, we studied a large thermal dataset recorded for 20 weeks and identified nine phenomena in it. Moreover, we investigated the impact of each phenomenon for model adaptation in transfer learning. Each phenomenon was investigated separately and in combination. the performance was analyzed by computing the F1 score, precision, recall, true negative rate, and false negative rate. Furthermore, to underline our investigation, the trained model with our dataset was further tested on publicly available datasets, and encouraging results were obtained. Finally, our dataset was also made publicly available.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {CNN,databases,dataset,deep learning,detection,images,model adaptation,outdoor,person,thermal},
  file = {/Users/lukas/Zotero/storage/2FVF44KL/Huda et al. - 2020 - The Effect of a Diverse Dataset for Transfer Learning in Thermal Person Detection.pdf}
}

@inproceedings{lecunHandwrittenDigitRecognition1989,
  title = {Handwritten {{Digit Recognition}} with a {{Back-Propagation Network}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {LeCun, Yann and Boser, Bernhard and Denker, John and Henderson, Donnie and Howard, R. and Hubbard, Wayne and Jackel, Lawrence},
  year = {1989},
  volume = {2},
  publisher = {Morgan-Kaufmann},
  urldate = {2025-08-13},
  abstract = {We present an application of back-propagation networks to hand(cid:173) written digit recognition. Minimal preprocessing of the data was  required, but architecture of the network was highly constrained  and specifically designed for the task. The input of the network  consists of normalized images of isolated digits. The method has  1 \% error rate and about a 9\% reject rate on zipcode digits provided  by the U.S. Postal Service.},
  file = {/Users/lukas/Zotero/storage/F3IHILBD/LeCun et al. - 1989 - Handwritten Digit Recognition with a Back-Propagation Network.pdf}
}

@misc{munirSSTNSelfSupervisedDomain2021,
  title = {{{SSTN}}: {{Self-Supervised Domain Adaptation Thermal Object Detection}} for {{Autonomous Driving}}},
  shorttitle = {{{SSTN}}},
  author = {Munir, Farzeen and Azam, Shoaib and Jeon, Moongu},
  year = {2021},
  month = nov,
  number = {arXiv:2103.03150},
  eprint = {2103.03150},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2103.03150},
  urldate = {2025-07-29},
  abstract = {The sensibility and sensitivity of the environment play a decisive role in the safe and secure operation of autonomous vehicles. This perception of the surrounding is way similar to human visual representation. The human's brain perceives the environment by utilizing different sensory channels and develop a view-invariant representation model. Keeping in this context, different exteroceptive sensors are deployed on the autonomous vehicle for perceiving the environment. The most common exteroceptive sensors are camera, Lidar and radar for autonomous vehicle's perception. Despite being these sensors have illustrated their benefit in the visible spectrum domain yet in the adverse weather conditions, for instance, at night, they have limited operation capability, which may lead to fatal accidents. In this work, we explore thermal object detection to model a view-invariant model representation by employing the self-supervised contrastive learning approach. For this purpose, we have proposed a deep neural network Self Supervised Thermal Network (SSTN) for learning the feature embedding to maximize the information between visible and infrared spectrum domain by contrastive learning, and later employing these learned feature representation for the thermal object detection using multi-scale encoder-decoder transformer network. The proposed method is extensively evaluated on the two publicly available datasets: the FLIR-ADAS dataset and the KAIST Multi-Spectral dataset. The experimental results illustrate the efficacy of the proposed method.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/lukas/Zotero/storage/MBDTUK77/Munir et al. - 2021 - SSTN Self-Supervised Domain Adaptation Thermal Object Detection for Autonomous Driving.pdf;/Users/lukas/Zotero/storage/9L6C5WVG/2103.html}
}

@misc{ruderOverviewGradientDescent2017,
  title = {An Overview of Gradient Descent Optimization Algorithms},
  author = {Ruder, Sebastian},
  year = {2017},
  month = jun,
  number = {arXiv:1609.04747},
  eprint = {1609.04747},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1609.04747},
  urldate = {2025-07-29},
  abstract = {Gradient descent optimization algorithms, while increasingly popular, are often used as black-box optimizers, as practical explanations of their strengths and weaknesses are hard to come by. This article aims to provide the reader with intuitions with regard to the behaviour of different algorithms that will allow her to put them to use. In the course of this overview, we look at different variants of gradient descent, summarize challenges, introduce the most common optimization algorithms, review architectures in a parallel and distributed setting, and investigate additional strategies for optimizing gradient descent.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Gradient Descent},
  note = {Comment: Added derivations of AdaMax and Nadam},
  file = {/Users/lukas/Zotero/storage/S3YP6J7P/Ruder - 2017 - An overview of gradient descent optimization algorithms.pdf;/Users/lukas/Zotero/storage/K8VX76QV/1609.html}
}

@article{tsaiUsingDeepLearning2022,
  title = {Using {{Deep Learning}} with {{Thermal Imaging}} for {{Human Detection}} in {{Heavy Smoke Scenarios}}},
  author = {Tsai, Pei-Fen and Liao, Chia-Hung and Yuan, Shyan-Ming},
  year = {2022},
  month = jan,
  journal = {Sensors},
  volume = {22},
  number = {14},
  pages = {5351},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1424-8220},
  doi = {10.3390/s22145351},
  urldate = {2025-08-12},
  abstract = {In this study, we propose using a thermal imaging camera (TIC) with a deep learning model as an intelligent human detection approach during emergency evacuations in a low-visibility smoky fire scenarios. We use low-wavelength infrared (LWIR) images taken by a TIC qualified with the National Fire Protection Association (NFPA) 1801 standards as input to the YOLOv4 model for real-time object detection. The model trained with a single Nvidia GeForce 2070 can achieve {$>$}95\% precision for the location of people in a low-visibility smoky scenario with 30.1 frames per second (FPS). This real-time result can be reported to control centers as useful information to help provide timely rescue and provide protection to firefighters before entering dangerous smoky fire situations.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {convolutional neural network,evacuation in fire,firefighter protection,human detection,human rescue,infrared thermal camera,LWIR,real-time object detection,smoky fire scene,thermal imaging camera,YOLO},
  file = {/Users/lukas/Zotero/storage/5R8BXD4N/Tsai et al. - 2022 - Using Deep Learning with Thermal Imaging for Human Detection in Heavy Smoke Scenarios.pdf}
}

@inproceedings{violaRapidObjectDetection2001,
  title = {Rapid Object Detection Using a Boosted Cascade of Simple Features},
  booktitle = {Proceedings of the 2001 {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}}. {{CVPR}} 2001},
  author = {Viola, P. and Jones, M.},
  year = {2001},
  volume = {1},
  pages = {I-511-I-518},
  publisher = {IEEE Comput. Soc},
  address = {Kauai, HI, USA},
  doi = {10.1109/CVPR.2001.990517},
  urldate = {2025-08-12},
  abstract = {This paper describes a machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates. This work is distinguished by three key contributions. The first is the introduction of a new image representation called the ``Integral Image'' which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features from a larger set and yields extremely efficient classifiers[6]. The third contribution is a method for combining increasingly more complex classifiers in a ``cascade'' which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. The cascade can be viewed as an object specific focus-of-attention mechanism which unlike previous approaches provides statistical guarantees that discarded regions are unlikely to contain the object of interest. In the domain of face detection the system yields detection rates comparable to the best previous systems. Used in real-time applications, the detector runs at 15 frames per second without resorting to image differencing or skin color detection.},
  isbn = {978-0-7695-1272-3},
  langid = {english}
}
